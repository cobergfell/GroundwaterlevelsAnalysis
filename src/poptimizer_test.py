# -*- coding: utf-8 -*-
"""
Created on Sun Jul 16 13:38:49 2023

@author: christophe
"""
# -*- coding: utf-8 -*-
"""
Created on Wed Mar  8 21:10:14 2023

@author: christophe
"""


# from scipy import interpolate
import os
import numpy as np
from scipy.optimize import least_squares, leastsq
from datetime import datetime
from matplotlib.pyplot import hist, figure, show,savefig,clabel,contour,setp,gcf,getp,gca,close
from matplotlib.ticker import Formatter,FuncFormatter, NullLocator, FixedLocator
from matplotlib.dates import date2num, num2date
from logging import getLogger
from stresstimeseries import Stress
from headstimeseries import Heads
from parameterslogistic import ParametersLogistic
from modeldefinition import ModelDefinition
from modelnoise import ResidualsDecayExponentially
from utilities import p_dict_copy
from harmonics import Harmonics
from harmonics_toolkit import *
from preprocessedseries import Preprocessed
from jacobian import Jacobian
from simulation import Simulation


class Poptimizer:
    

    """
        A class that provides instances of groundwater time series model parameters optimisation
    
        ...
    
    Attributes
    ----------
        
    time : numpy array_like
        Arrays of time numbers generated by matplotlib.dates function date2num
        when prepocessing the input time series using the preprocessedseries.py module
        
        
    _p_dict : python object of data type 'dict'
        _p_dict is a local copy of the p_dict dictionary defining the model parameters
        and associated specifications such as associated indexes, names, logtransformed or not, 
        variable or fixed etc. See the the parameterslogistic.py module for additional details.
        
    _stresses_dict : python object of data type 'dict'
        _stresses_dict is a local copy of the stresses_dict dictionary containing all the entered
        Stress objects used to explain the observed groundwater levels variations.
        
    heads : Heads object or list of Heads objects
        Single Heads object or list of Heads objects containing the observed groundwater levels,
        associated metadata and preprocessed versions of the groundwater level time series 

    settings : python object of data type 'dict' (optional)
        An optional dictionary of settings - not used in present version

    Nint_dict : python object of data type 'dict'
        A dictionary specifying per stress the memory of each stress, expressed 
        in number of time intervals (a time interval equals a time step)
        
    time_step : float
        The specified time step used for all heads and stresses time series     
          
    arguments_dict : python object of data type 'dict'
        A dictionary specifying additional arguments to pass to the response functions.
        For example: X,Y coordinates of pumping wells     
        
        
    time_boundaries_sim : python object of data type 'dict'
        A dictionary specifying the time boundaries of the simulation          
        
    time_boundaries_res : python object of data type 'dict'
        A dictionary specifying the time boundaries of the residuals (calibration period)         
        
    model_residuals : bool
        A boolean variable specifying if the residuals are modeled
        
    targets_weighting_method : string
        A string specifying the weighing methode (not implemented yet)     
        
    model_definition : Modeldefinition object
        A Modeldefinition object specifying how the time series analysis is implemented 
        (which is the first step in the present time series analysis methodology) 
        
    analytical_jacobian : boolean
        A boolean variable specifying if the jacobian is evaluated analytically (if possible)
        
    maxiter : int
        The maximum number of iterations imposed in an optimization proces       
    
    Methods
    -------

    residuals(p)    
        Evaluate the model residuals given parameters vector p.
        
    noise(p)  
        Evaluate the model noise given parameters vector p by modeling the residuals 
        in addition to the deterministic part of the model.

    goodness_of_fit(p)  
        Evaluate the model goodness of fit for a given parameters vector p by modeling the residuals 
        in addition to the deterministic part of the model.
        
    poptimizer_home_brew()  
        Parameters optimisation method; This is a non-linear least squares parameters optimisation method, 
        'home brewed', partly inspired by Hill, M. C. (1998); this home-brewed offers the possibility to 
        optimize parameters common to a list of Heads ojects or to optimizing the parameters under the additional 
        constraint of harmonics components consistency.        

    scipy_optimize_least_squares()  
        Parameters optimisation method using scipy.least_squares method; only applicable for a single
        Heads object (so not for a list of Heads objects).
        Note: this optimisation method is only used for testing and comparisons purposes. Using the 
        poptimizer_home_brew method is preferable because it offers options such as optimizing parameters 
        common to a list of Heads ojects or optimizing the parameters under the additional constraint of 
        harmonics components consistency.
                
    scipy_optimize_leastsq()  
        Parameters optimisation method using scipy.leastsq (now deprecated) method; only applicable for a single
        Heads object (so not for a list of Heads objects).
        Note: for the same reasons as for the scipy_optimize_least_squares() using the poptimizer_home_brew method is 
        preferable (see notes by scipy_optimize_least_squares()).
        
    jacfunc(p,func, selectlog = None ,delp = 0.05)  
        Method to estimate the jacobian of a function 'func' for a given parameters vector p 
        using a finite difference approach.       
        
    jacfunc_with_harmonics(p,func, p_dict, stresses_dict, heads, selectlog = None, selectparam = None, delp = 0.05)  
        Method similar to jacfunc, adapted to constrain the model ny requiring the consistency of the 
        harmonic components.
   
    jacanalytical(p)  
        Method similar to estimate the analytical jacobian of a model (when possible).



    Example
    --------
    
    abs_path = os.path.dirname(os.path.abspath(__file__))
    abs_path_splitted = abs_path.split('\\')
    path_to_parent_folder_elements = abs_path_splitted[:-1]
    path_to_parent_folder = os.path.join(*path_to_parent_folder_elements)
    splitted = path_to_parent_folder.split(':')#trick  to  repair  path
    path_to_parent_folder = splitted[0]+':\\'+splitted[1]#trick  to  repair  path
    path_to_file_folder = os.path.join(path_to_parent_folder,'resources') 
    
    stresses_dict = {}

    path_to_file = os.path.join(path_to_file_folder,'672_PREC_Hellendoorn_19510101_20160731_corrected_for_interception2mm.csv')
    path_to_file = os.path.join(path_to_file_folder,'672_PREC_Hellendoorn_19510101_20160731.csv')
    
    key = basename(path_to_file)
    stresses_dict['prec'] = {}
    stresses_dict['prec'][key] = Stress.read_from_csv(path_to_file, stress_type = 'prec',cumulative = True)    

    path_to_file=os.path.join(path_to_file_folder,'260_De_Bilt_EVAP_19010101_20131015.csv')
   
    key = basename(path_to_file)
    stresses_dict['evap'] = {}
    stresses_dict['evap'][key] = Stress.read_from_csv(path_to_file, stress_type = 'evap',cumulative = True)    

    
    tminstr = '31-12-1981 00:00:00'
    tmaxstr = '31-12-1995 00:00:00'    
    
    path_to_file_folder = os.path.join(path_to_parent_folder,'resources')  
    path_to_file = os.path.join(path_to_file_folder,'28AP0093_1.txt')
    heads = Heads.read_from_csv(path_to_file, tminstr = tminstr, tmaxstr = tmaxstr)

    arguments_dict = {}

    for key in stresses_dict:
        for e in stresses_dict[key]:
            stresses_dict[key][e].plot()

    md = ModelDefinition().model_definition
    memory_dict = ModelDefinition().memory_dict
    parametersLogistic = ParametersLogistic(md)
    
    time_step = 1.
    time_step_targets = 14.
    
    
    preprocessed = Preprocessed(heads = heads,stresses_dict = stresses_dict, time_step = time_step,
                                time_step_targets = time_step_targets, memory_dict = memory_dict,tminstr = tminstr, 
                                tmaxstr = tmaxstr, model_definition = md).preprocess() 
        
    time = preprocessed.time
    time_step = preprocessed.time_step
    heads = preprocessed.heads

    stresses_dict = preprocessed.stresses_dict 
    Nint_dict = preprocessed.Nint_dict
    all_data_for_neural_networks = preprocessed.all_data_for_neural_networks
    all_targets_for_neural_networks = preprocessed.all_targets_for_neural_networks        
        
    if isinstance(heads,list):
        _heads = heads[0]
    else:
        _heads = heads    
 
    parametersLogistic = ParametersLogistic(md,stresses_dict = stresses_dict, heads = _heads)
    p_dict = parametersLogistic.assemble_p()

    potimizer = Poptimizer(heads = heads, time = time, p_dict = p_dict, time_step = time_step,
                            stresses_dict = stresses_dict, model_residuals = True, model_definition = md,
                            Nint_dict = Nint_dict, arguments_dict = arguments_dict, settings = settings,
                            analytical_jacobian = False)    
    
    popt, pcov, pcor, pstdev, p_dict, expvar, expvarnoise  = potimizer.poptimizer_home_brew()    

    
    plotax = heads.plot()
    output_string = heads.generate_output(model_definition = md)
    print('output_string)  

   
    """  
    
    logger = getLogger(__name__)
        
    def __init__(self, heads = None, time = None, p_dict = None, arguments_dict = None, 
                 stresses_dict = None, model_residuals = False, time_step = None, time_step_targets = None, Nint_dict = None, 
                 time_boundaries_sim = None ,time_boundaries_res = None, settings = None, maxiter = 50,
                 targets_weighting_method = None, model_definition = None, analytical_jacobian = False):
           
        clsname = str(self.__class__.__name__)
        modulename = str(__name__) 
        

        #local copy of mutable input dictionaries
        _p_dict = {}
        for key in p_dict:
            _p_dict[key] = p_dict[key]
            
        _stresses_dict = {}
        for key in stresses_dict:
            _stresses_dict[key] = stresses_dict[key]          
            

        self.time = time
        self._p_dict = _p_dict
        self._stresses_dict = _stresses_dict
        self.heads = heads
        self.settings = settings
        self.Nint_dict = Nint_dict
        self.time_step = time_step
        self.time_step_targets = time_step_targets
        self.arguments_dict = arguments_dict
        self.time_boundaries_sim = time_boundaries_sim
        self.time_boundaries_res = time_boundaries_res
        self.model_residuals = model_residuals
        self.targets_weighting_method = targets_weighting_method
        self.model_definition = model_definition
        
        
        if 'noise' in model_definition:
            if model_definition['noise']['model_residuals'] == False:
                self.model_residuals = False
       
        # overrule model definition if keyword argumenent  model_residuals = True
        if model_residuals == True:
            self.model_residuals = True
                
                  
        # Limitatiosn on the computation of the analytical jacobian        
        if model_definition['root_zone']['apply_root_zone'] == True:
            analytical_jacobian = False

        if model_definition['prec']['number_of_regimes'] > 1:                
            analytical_jacobian = False                
        
        self.analytical_jacobian = analytical_jacobian
        self.maxiter = maxiter        

        def __repr__(self):
            """Prints the optimisation context."""
            textToFormat = ('Optimisation class: {cls}'
                        'model_residuals ={self.model_residuals}')
                        
            return textToFormat.format(cls=self.__class__.__name__,
                                   model_residuals=self.model_residuals)


    
    def residuals(self,p, heads = None):   
        
        """
        Method that returns the residuals of a time series model
        
        Parameters
        ----------
        p: numpy array_like
                array containing the parameters vector
                
        time : numpy array_like
            Arrays of time numbers generated by matplotlib.dates function date2num
            when prepocessing the input time series using the preprocessedseries.py module
            
        heads : Heads object or list of Heads objects
            Single Heads object or list of Heads objects containing the observed groundwater levels,
            associated metadata and preprocessed versions of the groundwater level time series             
                
    
        Returns
        -------
        res: numpy array_like
                array of residuals with dimension 1 x number of calibration targets
        
        """

      
        time = self.time
        p_dict = self._p_dict
        arguments_dict = self.arguments_dict
        stresses_dict = self._stresses_dict
        settings = self.settings
        Nint_dict =self. Nint_dict
        time_step = self.time_step
        time_boundaries_sim = self.time_boundaries_sim
        time_boundaries_res = self.time_boundaries_res
        targets_weighting_method = self.targets_weighting_method
        model_residuals = self.model_residuals
        md = self.model_definition

        
        p_dict = p_dict_copy(self._p_dict)

        isvariable = p_dict['isvariable']
        
        if model_residuals == False:
            if 'noise' in p_dict['p_indexes']:
                indices = p_dict['p_indexes']['noise']['regime_1']['basicparam']
                for index in indices:
                    isvariable[index] = False

        
        if heads is None:
            _heads = self.heads
        else:
            _heads = heads
            
        all_piezometers_share_same_model = False
        if isinstance(_heads, list):
            if 'all_piezometers_share_same_model' in settings:
                if settings['all_piezometers_share_same_model'] == True:
                    all_piezometers_share_same_model = True
                
        isvariable = p_dict['isvariable']
        p_complete = np.array(p_dict['p_init'])
        mask = np.array(isvariable)
        p_complete[mask] = p
        p_dict['p'] = p_complete.tolist()
      
        
        if time_boundaries_sim is not None:
            tmin_sim, tmax_sim = unpack_time_boundaries(time_boundaries_sim)
        else:
            tmin_sim = time[0]
            tmax_sim = time[-1]
            
            
        if time_boundaries_res is not None:
            tmin_res, tmax_res = unpack_time_boundaries(time_boundaries_res)
        else:
            tmin_res = time[0]
            tmax_res = time[-1]            

        if all_piezometers_share_same_model == True:
            simulations_list = []
            targets_list = []
            targets_selector_list = []
            targets_weights_list = []
            names_list = []
            
            Nt = 0 # total number of targets
            for heads in _heads:

                sim = Simulation(time = time, p_dict = p_dict, stresses_dict = stresses_dict, 
                                 heads = heads, time_step = time_step, Nint_dict = Nint_dict, 
                                 tminnum = tmin_sim, tmaxnum = tmax_sim, settings = settings, 
                                 model_residuals = False, model_definition = md).simulate()
                      
                targets = heads.targets

                Nt += len(targets)
                     
                targets_selector = heads.targets_selector 

                simulations_list.append(sim)
                targets_list.append(targets)
                targets_selector_list.append(targets_selector)
                names_list.append(heads.name)
                
                if heads.weights is not None:
                    targets_weights_list.append(heads.weights)
                else:
                    targets_weights_list.append(np.ones(len(targets),dtype=int))                
                                
            res = np.empty(Nt)   
            index_begin = 0
            for i in range(0,len(targets_list)):
                sim = simulations_list[i]
                targets = targets_list[i]
                targets_selector = targets_selector_list[i]
                weights = targets_weights_list[i]
                
                nt = len(targets) # number of targets of that specific time series
                index_end = index_begin + nt

                res[index_begin:index_end] = targets[:,1]-sim[targets_selector,1]
                
                res[index_begin:index_end] = np.multiply(res[index_begin:index_end],weights)
                index_begin = index_end

        else:
            sim = Simulation(time = time, p_dict = p_dict, stresses_dict = stresses_dict, 
                             heads = _heads, time_step = time_step, Nint_dict = Nint_dict, 
                             tminnum = tmin_sim, tmaxnum = tmax_sim, settings = settings, 
                             model_residuals = False, model_definition = md).simulate()
            
            targets = _heads.targets
            targets_selector = _heads.targets_selector 
    
            res = targets[:,1]-sim[targets_selector,1]
            
            if _heads.weights is not None:
                try:
                    res = np.multiply(res,_heads.weights)
    
                except:
                    logger.warning("residuals could not be weighted, all weights are set equal to 1 ")
                finally:   
                    
                    weights = np.ones(len(res),dtype=int)
                    res = np.multiply(res,weights)

        return res     





    def noise(self,p ,heads = None):   
        
        """
        Method that returns the remaing noise after trying to model the 
        observed groundwater levels with stress specific response functions and
        the residual wit a residual model
        
        Parameters
        ----------
        p: numpy array_like
                array containing the parameters vector
                
        time : numpy array_like
            Arrays of time numbers generated by matplotlib.dates function date2num
            when prepocessing the input time series using the preprocessedseries.py module
            
        heads : Heads object or list of Heads objects
            Single Heads object or list of Heads objects containing the observed groundwater levels,
            associated metadata and preprocessed versions of the groundwater level time series
    
        Returns
        -------
        v: numpy array_like
                array of noise terms with dimension 1 x number of calibration targets
        
        """
      
        time = self.time
        arguments_dict = self.arguments_dict
        stresses_dict = self._stresses_dict
        settings = self.settings
        Nint_dict =self. Nint_dict
        time_step = self.time_step
        time_boundaries_sim = self.time_boundaries_sim
        time_boundaries_res = self.time_boundaries_res
        targets_weighting_method = self.targets_weighting_method
        md = self.model_definition
                
        if time_boundaries_sim is not None:
            tmin_sim, tmax_sim = unpack_time_boundaries(time_boundaries_sim)
        else:
            tmin_sim = time[0]
            tmax_sim = time[-1]
                        
        if time_boundaries_res is not None:
            tmin_res, tmax_res = unpack_time_boundaries(time_boundaries_res)
        else:
            tmin_res = time[0]
            tmax_res = time[-1]       
          
        p_dict = p_dict_copy(self._p_dict)
        isvariable = p_dict['isvariable']
        p_complete = np.array(p_dict['p_init'])
        mask = np.array(isvariable)
        p_complete[mask] = p
        p_dict['p'] = p_complete.tolist()
        
          
        if heads is None:
            _heads = self.heads
        else:
            _heads = heads
            
        all_piezometers_share_same_model = False
        if isinstance(_heads, list):
            if 'all_piezometers_share_same_model' in settings:
                if settings['all_piezometers_share_same_model'] == True:
                    all_piezometers_share_same_model = True 


        if all_piezometers_share_same_model == True:
            noises_list = []

            Nt = 0 # total number of targets
            
            for heads in _heads:
                

                sim = Simulation(time = time, p_dict = p_dict, stresses_dict = stresses_dict, 
                                 heads = heads, time_step = time_step, Nint_dict = Nint_dict, 
                                 tminnum = tmin_sim, tmaxnum = tmax_sim, settings = settings, 
                                 model_residuals = False, model_definition = md).simulate()
                
                targets = heads.targets
                Nt += len(targets)
                                                         
                noisefunctclassname = p_dict['componentsnames']['noise']
                # v = eval( noisefunctclassname + "(p_dict = p_dict, time = time, heads = heads, deterministic_simulation = sim, targets_weighting_method = targets_weighting_method).model_residuals()")
                v = eval( noisefunctclassname + "(p_dict = p_dict, time = time, heads = heads,"
                         +"deterministic_simulation = sim, targets_weighting_method = targets_weighting_method).estimate_noise()")

                v = v[:,1]                

                noises_list.append(v)
                
            v = np.empty(Nt)   
            index_begin = 0
            for i in range(0,len(noises_list)):
                noise = noises_list[i]

                nt = len(noise) # number of targets of that specific time series
                index_end = index_begin + nt
                
                v[index_begin:index_end] = noise[:]

                index_begin = index_end
         
        else:            
            sim = Simulation(time = time, p_dict = p_dict, stresses_dict = stresses_dict, 
                     heads = _heads, time_step = time_step, Nint_dict = Nint_dict, 
                     tminnum = tmin_sim, tmaxnum = tmax_sim, settings = settings, 
                     model_residuals = False, model_definition = md).simulate()
                    
            noisefunctclassname = p_dict['componentsnames']['noise']
            v = eval( noisefunctclassname + "(p_dict = p_dict, time = time, heads = _heads, deterministic_simulation = sim, targets_weighting_method = targets_weighting_method).estimate_noise()")
            v = v[:,1]

        return v 
   

          

    
    def scipy_optimize_least_squares(self):
        
        """
        
        Method to optimize parameters based on scipy.optimize.least_squares to
        solve a nonlinear least-squares problem with bounds on the variables.
        see https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.least_squares.html
        
        
        Returns
        -------

        popt:  numpy array_like
            array of optimal parameters           
            
        pcov:  numpy array_like
            parameters covariance matrix             
            
        pcor:  numpy array_like
            parameters correlation matrix  
            
        stderr:  numpy array_like
            parameters standard error (= standard deviation)     
            
        p_dict : python object of data type 'dict'
            updated model parameters dictionary 
           
        EV : float
            model explained variance (similar to Nash-Sutcliffe coefficient)            
            
        mae : float
            mean absolute error             
   
        """
        
        
        p_dict = self._p_dict 
        p_init = p_dict['p_init']
        model_residuals = self.model_residuals
        
        isvariable = p_dict['isvariable']
        if model_residuals == False:
            if 'noise' in p_dict['p_indexes']:
                indices = p_dict['p_indexes']['noise']['regime_1']['basicparam']
                for index in indices:
                    isvariable[index] = False
                
        p_complete = np.array(p_dict['p_init'])
        lb = np.array(p_dict['p_min'])
        ub = np.array(p_dict['p_max'])
        mask = np.array(isvariable)
        p_init = p_complete[mask]
        lb = lb[mask]
        ub = ub[mask]
        bounds = (lb, ub)

        popt = None
        pcov = None
        pcor = None
        stderr = None
        EV = None
        mae = None

        outcome = least_squares(self.residuals, x0 = p_init, bounds=bounds,args=(), kwargs={},method='trf', ftol=1e-08, xtol=1e-08, gtol=1e-08, x_scale=1.0, loss='linear', f_scale=1.0, diff_step=None, tr_solver=None, tr_options={}, jac_sparsity=None, max_nfev=None, verbose=0)
        
        popt = outcome['x']
        success = outcome['success']
        cost = outcome['cost']
        res = outcome['fun']
        jac = outcome['jac']
        message = outcome['message']
        
    
        if success == True:  
            JTJ = np.dot(np.transpose(jac),jac)
            pvar = np.var(res)
            pcov = np.linalg.inv(JTJ)*np.var(res)
            pvar = np.diag(pcov)#parameters variance vector
            stderr = np.sqrt(pvar)#parameters standard deviation vector
            outer_product = np.outer(stderr,stderr)#outer product of standard error vector
            pcor = pcov / outer_product 
            res, EV, mae = self.goodness_of_fit(popt)


        if pcov is None :
            logger.warning("Failed finding a significant parameters optimal vector")
            
        # finally update p_dict with popt
        update_p_dict_from_p(p_dict, popt)
        
        
        return popt, pcov, pcor, stderr, p_dict, EV, mae    
    




    def scipy_optimize_leastsq(self):
        
        """
        Method to optimize parameters based on scipy.optimize.leastsq, 
        the scipy.optimize legacy wrapper for the MINPACK 
        implementation of the Levenberg-Marquadt algorithm.
        
        Returns
        -------

        popt:  numpy array_like
            array of optimal parameters           
            
        pcov:  numpy array_like
            parameters covariance matrix             
            
        pcor:  numpy array_like
            parameters correlation matrix  
            
        stderr:  numpy array_like
            parameters standard error (= standard deviation)     
            
        p_dict : python object of data type 'dict'
            updated model parameters dictionary 
           
        EV : float
            model explained variance (similar to Nash-Sutcliffe coefficient)            
            
        mae : float
            mean absolute error          
        
        
        """
        
        
        
        p_dict = self._p_dict 
        p_init = self._p_dict ['p_init']
        heads = self.heads
        model_residuals = self.model_residuals
        
        
        isvariable = p_dict['isvariable']
        
        if model_residuals == False:
            if 'noise' in p_dict['p_indexes']:
                indices = p_dict['p_indexes']['noise']['regime_1']['basicparam']
                for index in indices:
                    isvariable[index] = False
                

        p_complete = np.array(p_dict['p_init'])
        mask = np.array(isvariable)
        p_init = p_complete[mask]
        
        

        popt = None
        pcov = None
        pcor = None
        stderr = None
        EV = None
        mae = None
        
        if model_residuals == True:
            if heads is not None:
                outcome = leastsq(self.noise,p_init,args=(),full_output=1,Dfun=None, col_deriv=0, ftol=1.49012e-10, xtol=1.49012e-12, gtol=0.0, maxfev=0, epsfcn=0.0, factor=0.1, diag=None)
        
            else:
                logger.warning("Heads must be provided to model noise")            
        else: 
            outcome = leastsq(self.residuals,p_init,args=(),full_output=1,Dfun=None, col_deriv=0, ftol=1.49012e-10, xtol=1.49012e-12, gtol=0.0, maxfev=0, epsfcn=0.0, factor=0.1, diag=None)
        
        
        popt = outcome[0]

        err = self.residuals(popt)
    
        if outcome[1] is not None:                                    
            pcov=np.var(err)*outcome[1]
            pvar=np.diag(pcov)#parameters variance vector
            stderr=np.sqrt(pvar)#parameters standard deviation vector
            outer_product=np.outer(stderr,stderr)#outer product of standard error vector
            pcor=pcov/outer_product 
            res, EV, mae = self.goodness_of_fit(popt)

        if pcov is None :
            logger.warning("Failed finding a significant parameters optimal vector")
            

        # finally update p_dict with popt
        update_p_dict_from_p(p_dict, popt)
        

        return popt, pcov, pcor, stderr , p_dict, EV, mae    
    
    
    
    def jacfunc(self,p,func, selectlog = None ,delp = 0.05):
        
        """
            Method that evaluates the jacobian of function func using a finite difference estimation.
    
            Parameters
            ----------
            p: numpy array_like
                vector of current parameters
                
            func: string
                function name (callback)
                
            selectlog: numpy array_like of booleans
                vector of booleans values for which True indicates a logtransformed parameter   

            delp: float
                fraction of parameters used to isvariable the parameter in the finite differenciation
    
            Returns
            -------
            J: numpy array_like
                2 dimensional array of jacobian elements (the first order partial 
                                                          of the model at each calibration point) 
    
    
                
        """ 
        
        delp = 0.05
        current = func(p)
        nl = len(current) #number of jacobian lines
        nc = len(p) #number of jacobian columns
        J = np.empty((nl,nc))
        p = np.array(p) #from list type to array type in order to perform the additionb P+dP

        
        dp = abs(p)*delp #del p for non log transformed parameters
        dp[selectlog] = np.log(delp+1) #replace dp for log transformed parameters 
        dp = np.diag(dp) #diagonal matrix of perturbations
        p = p + np.zeros((len(p),len(p))) #this is python broadcasting: result is a square matrix of length P
        pp = p + dp
        pm = p - dp #pp for 'p plus' and pm for 'p min'

        
        for j in range(0,nc):
            # the minus sign below is to compensate for the fact that we do not substract errors = targets -func but the function self
            J[:,j] = -(func(pp[j,:])-func(pm[j,:]))/(pp[j,j]-pm[j,j]) 
    
        return J
        
  
    def jacfunc_with_harmonics(self,p,func, p_dict, stresses_dict, heads, selectlog = None, selectparam = None, delp = 0.05):
        
        """
            Method that evaluates the jacobian of function func using a finite difference estimation,
            taking into account the constraint on the consistency of the harmonic componenets.
        
            Parameters
            ----------
            p: numpy array_like
                vector of current parameters
                
            func: string
                function name (callback)
                
            p_dict : python object of data type 'dict'
                updated model parameters dictionary     
                
            stresses_dict : python object of data type 'dict'
                stresses dictionary containing the Stress objects used to explained
                the observed groundwater level variations
                
            heads : Heads object or list of Heads objects
                Single Heads object or list of Heads objects containing the observed groundwater levels,
                associated metadata and preprocessed versions of the groundwater level time series                 
                
                               
            selectlog: numpy array_like of booleans
                vector of booleans values for which True indicates a logtransformed parameter   
                
            selectparam: numpy array_like of booleans
                vector of booleans values selecting variable parameters                
                

            delp: float
                fraction of parameters used to perturb parameters in the finite differenciation
    
            Returns
            -------
            J: numpy array_like
                2 dimensional array of jacobian elements (the first order partial 
                                                          of the model at each calibration point) 
    
    
                
        """ 

        nparam = len(p_dict['p_init'])
        if selectlog is None:
            selectlog = np.zeros(nparam, dtype = bool)
        if selectparam is None:
            selectparam = np.ones(nparam, dtype = bool)

        current = func(p)
        nl = len(current) #number of jacobian lines
        nc = len(p) #number of jacobian columns
        J = np.empty((nl,nc))
        p = np.array(p) #from list type to array type in order to perform the additionb P+dP
        dp = abs(p)*delp #del p for non log transformed parameters
        if selectlog is not None:
            dp[selectlog] = np.log(delp+1) #replace dp for log transformed parameters 
        dp = np.diag(dp) #diagonal matrix of perturbations
        p = p + np.zeros((len(p),len(p))) #this is python broadcasting: result is a square matrix of length P, with each line=P
        pp = p + dp
        pm = p - dp #pp for 'p plus' and pm for 'p min'

        
        for j in range(0,nc):
        
            if 'prec' in self.model_definition['constrain_with_harmonics']:
                p_full = p_dict['p_init']
                p_full = np.array(p_full)
                p_full[selectparam] = pp[j,:]
                p_dict['p'] = p_full.tolist()
                p_dict = update_P_given_harmonic_components(p_dict, stresses_dict, heads) 
                p_full = p_dict['p']
                p_full = np.array(p_full)
                pp[j,:] = p_full[selectparam]
                
                
                p_full = p_dict['p_init']
                p_full = np.array(p_full)
                p_full[selectparam] = pm[j,:]
                p_dict['p'] = p_full.tolist()
                p_dict = update_P_given_harmonic_components(p_dict, stresses_dict, heads) 
                p_full = p_dict['p']
                p_full = np.array(p_full)
                pm[j,:] = p_full[selectparam]               

            
            # the minus sign below is to compensate for the fact that we do not substract errors = targets -func but the function self
            J[:,j] = -(func(pp[j,:])-func(pm[j,:]))/(pp[j,j]-pm[j,j])
   
        return J    
    
    
    def jacanalytical(self,p):
        
        """
        
            Method that evaluates the analytical jacobian of the time series model.
    
            Parameters
            ----------
            p: numpy array_like
                vector of current parameters
                
            Returns
            -------
            J: numpy array_like
                2 dimensional array of jacobian elements (the first order partial 
                                                          of the model at each calibration point) 
 
        """ 
        
        time = self.time
        p_dict = self._p_dict
        arguments_dict = self.arguments_dict
        stresses_dict = self._stresses_dict
        settings = self.settings
        Nint_dict =self. Nint_dict
        time_step = self.time_step
        time_boundaries_sim = self.time_boundaries_sim
        time_boundaries_res = self.time_boundaries_res
        targets_weighting_method = self.targets_weighting_method
        model_residuals = self.model_residuals
        md = self.model_definition


        p_dict = p_dict_copy(self._p_dict)

        isvariable = p_dict['isvariable']
        
        if model_residuals == False:
            if 'noise' in p_dict['p_indexes']:
                indices = p_dict['p_indexes']['noise']['regime_1']['basicparam']
                for index in indices:
                    isvariable[index] = False

        _heads = self.heads

        all_piezometers_share_same_model = False
        if isinstance(_heads, list):
            if 'all_piezometers_share_same_model' in settings:
                if settings['all_piezometers_share_same_model'] == True:
                    all_piezometers_share_same_model = True
                
        isvariable = p_dict['isvariable']
        p_complete = np.array(p_dict['p_init'])
        mask = np.array(isvariable)
        p_complete[mask] = p
        p_dict['p'] = p_complete.tolist()
      
        
        if time_boundaries_sim is not None:
            tmin_sim, tmax_sim = unpack_time_boundaries(time_boundaries_sim)
        else:
            tmin_sim = time[0]
            tmax_sim = time[-1]
            
            
        if time_boundaries_res is not None:
            tmin_res, tmax_res = unpack_time_boundaries(time_boundaries_res)
        else:
            tmin_res = time[0]
            tmax_res = time[-1]            

        if all_piezometers_share_same_model == True:
            jacobians_lengths_list = []
            names_list = []
            
            # first find the dimensions of the jacobian matrix
            
            # nl is the number of lines of the jacobian matrix
            nl = 0
            for heads in _heads:
                n = len(heads.targets)
                nl += n
                names_list.append(heads.name) # name list is only for use for debugging purposes
                jacobians_lengths_list.append(n)

                
            nc = len(p)
                
            J = np.empty((nl,nc))
            index_begin = 0    
            for i in range(0,len(_heads)):
                n = jacobians_lengths_list[i]
                heads = _heads[i]
                index_end = index_begin + n

                simulation = Simulation(time = time, p_dict = p_dict, stresses_dict = stresses_dict, 
                                 heads = heads, time_step = time_step, Nint_dict = Nint_dict, 
                                 tminnum = tmin_sim, tmaxnum = tmax_sim, settings = settings, 
                                 model_residuals = model_residuals, model_definition = md)
                
                
                jac = Jacobian(simulation).evaluate()
                
                J[index_begin:index_end,:] = jac    
                
                index_begin = index_end  

        else:

            simulation = Simulation(time = time, p_dict = p_dict, stresses_dict = stresses_dict, 
                             heads = _heads, time_step = time_step, Nint_dict = Nint_dict, 
                             tminnum = tmin_sim, tmaxnum = tmax_sim, settings = settings, 
                             model_residuals = model_residuals, model_definition = md)

            J = Jacobian(simulation).evaluate()
            
        return J




    def goodness_of_fit(self, p, noise = False, heads = None):   
        
        """
        Method that returns the goodness of fit of a time series model
        
        Parameters
        ----------
        p: numpy array_like
                array containing the parameters vector
                
        noise: boolean
            boolean value indicating if the goodness of fit corresponds to
            the model residuals (model includes only stress related functions) 
            or to the model noise (in which case the residuals are also modeled)
           
        heads : Heads object or list of Heads objects
            Single Heads object or list of Heads objects containing the observed groundwater levels,
            associated metadata and preprocessed versions of the groundwater level time series             
                   
        Returns
        -------
        EV : float
            model explained variance (similar to Nash-Suttcliffe coefficient)            
            
        mae : float
            mean absolute error   
        
        """        

        all_piezometers_share_same_model = False
        
        if heads is None:
            _heads = self.heads
        else:
            _heads = heads
            
        if isinstance(_heads, list):
            if 'all_piezometers_share_same_model' in self.settings:
                if self.settings['all_piezometers_share_same_model'] == True:
                    all_piezometers_share_same_model = True
                
        if all_piezometers_share_same_model == True:
            
            if noise == True: 
                
                err = self.noise(p)           
            else:
                err  = self.residuals(p)
                       
            Nt = 0
            targets_list = []
            targets_weights_list = []
            
            for heads in self.heads:
                targets = heads.targets
                Nt += len(targets)
                targets_list.append(targets)
                
                if heads.weights is not None:
                    targets_weights_list.append(heads.weights)
                else:
                    targets_weights_list.append(np.ones(len(targets),dtype=int))         
                   
            targets_multiple_series = np.empty((Nt,2))   
            weights_multiple_series = np.empty(Nt)   
            observed_deviations_from_mean = np.empty(Nt)   
          
            index_begin = 0
            for i in range(0,len(targets_list)):
                targets = targets_list[i]
                weights = targets_weights_list[i]
                nt = len(targets) # number of targets of that specific time series
                index_end = index_begin + nt
                targets_multiple_series[index_begin:index_end,:] = targets
                weights_multiple_series[index_begin:index_end] = weights
                observed_deviations_from_mean[index_begin:index_end] = targets[:,1]-np.mean(targets[:,1]) 
                index_begin = index_end

        else:
            if noise == True:
                err = self.noise(p, heads = _heads)
            else:
                err = self.residuals(p, heads = _heads)
            targets = _heads.targets
            observed_deviations_from_mean = targets[:,1]-np.mean(targets[:,1])  
        mae = np.mean(abs(err))        
        SSreg = sum(pow(err,2))
        SStot = sum(pow(observed_deviations_from_mean,2))
        EV = 100*(1-SSreg/SStot)

        return EV, mae 





    
    
    def poptimizer_home_brew(self):
        
        """
        
        Non-linear least squares optimisation method partly based on Hill, M. C. (1998); 
        this 'home-brewed' version offers the possibility to optimize parameters common to 
        a list of Heads ojects or to optimizing the parameters under the additional 
        constraint of harmonics components consistency.      
        
        
        Parameters
        ----------
        The parameters needed are entered by initializing the class object, see Class documentation
        
    
        References
        ----------

        Hill, M. C. (1998), Methods and guidelines for effective model calibration Rep. Open-file Rep 98-4005, USGS.
        
        Cooley, R.L., 1993, Regression modeling of ground-water flow, Supplement 1 -- Modifications to
        the computer code for nonlinear regression solution of steady-state ground-water flow problems:
        U.S Geological Survey Techniques of Water Resources Investigations, book 3, chapt.
        B4, supplement 1, 8p.
        
        
        Note
        ----------
        Although the present method does not follow the Levenberg Marquardt algorithm, an 
        accessible introduction to non-linear least-squares optimisation with a clear pseudo code 
        is given in 'Brief Description of the Levenberg-Marquardt Algorithm Implemened by levmar,
        Lourakis, M.I.A., 2005
        
        
        """
        from numpy import var,std,dot,diag, transpose,sqrt
        from numpy.linalg import solve,inv,det,LinAlgError
        from scipy.linalg import diagsvd

        clsname = str(self.__class__.__name__)
        modulename = str(__name__)   


        arguments_dict = self.arguments_dict
        p_dict = self._p_dict 
        p_init = p_dict['p_init']
        time = self.time
        heads = self.heads
        stresses_dict = self._stresses_dict
        settings = self.settings
        Nint_dict = self.Nint_dict
        time_step = self.time_step
        model_residuals = self.model_residuals
        time_boundaries_sim = self.time_boundaries_sim
        time_boundaries_res = self.time_boundaries_res
        md = self.model_definition
        analytical_jacobian = self.analytical_jacobian
        

        
        all_piezometers_share_same_model = False
        if isinstance(self.heads, list):
            if 'all_piezometers_share_same_model' in settings:
                if settings['all_piezometers_share_same_model'] == True:
                    all_piezometers_share_same_model = True        
        
        if time is None:
            message = (f'\nIn class {clsname} of module {modulename}.py: No valid time period is available for the analysis.\n ')                      
            logger.warning(message)   
            
               
        if time_boundaries_sim is not None:
            tmin_sim, tmax_sim = unpack_time_boundaries(time_boundaries_sim)
        else:
            tmin_sim = time[0]
            tmax_sim = time[-1]
            
            
        if time_boundaries_res is not None:
            tmin_res, tmax_res = unpack_time_boundaries(time_boundaries_res)
        else:
            tmin_res = time[0]
            tmax_res = time[-1]    
        
        
        isvariable = []
        for e in p_dict['isvariable']:
            isvariable.append(e)

        if model_residuals == False:
            if 'noise' in p_dict['p_indexes']:
                indices = p_dict['p_indexes']['noise']['regime_1']['basicparam']
                for index in indices:
                    isvariable[index] = False
                    
                    
                    
        #replace initial residual model decay exponent by time_step_targets as initial value
        if model_residuals == True:
            if 'noise' in p_dict['p_indexes']:
                indices = p_dict['p_indexes']['noise']['regime_1']['basicparam']
                if len(indices) == 1: #applicabale only for exponential decay
                    index = indices[0]
                    if self.time_step_targets is not None:
                        new_alpha = self.time_step_targets
                        p_dict['p'][index] = new_alpha
                        if p_dict['logtransform'][index] == True:
                            p_dict['p'][index] = np.log(new_alpha)

    
                    
        isvariable_det = []
        for e in isvariable:
            isvariable_det.append(e)
            
        if 'noise' in p_dict['p_indexes']:
            indices = p_dict['p_indexes']['noise']['regime_1']['basicparam']
            for index in indices:
                isvariable_det[index] = False

        logtransform = []
        for e in p_dict['logtransform']:
            logtransform.append(e)        
        
        selectparam = np.array(isvariable) # selectparam select variable parameters
        selectparam_det = np.array(isvariable_det) # selectparam_det select variable parameters except those used in noise model
        
        
        selectlog = np.array(logtransform)[selectparam] # selectlog elements are True when a variable parameter is logtransformed
        selectlog_det = np.array(logtransform)[selectparam_det]

        p_init = np.array(p_dict['p_init'])
        popt = p_init[selectparam]

        eps1 = 1e-10
        eps2 = 1e-10
        eps3 = 1e-10
        maxiter = self.maxiter

        delpdef = 0.05 # default delp
        delp = delpdef
        best_score = -1e9
        best_p = p_init
        best_dp = np.zeros(len(p_init))

        p_dict['p'] = p_dict['p_init']

        if 'prec' in self.model_definition['constrain_with_harmonics']:
            p_dict = update_P_given_harmonic_components(p_dict, stresses_dict, heads)

        res_old = self.residuals(popt)
        expvarold = self.goodness_of_fit(popt)[0]


        print('1275  analytical_jacobian flag: ',analytical_jacobian)
        input()
        
        if model_residuals == False:
                     
            if analytical_jacobian == True:
                J = self.jacanalytical(popt)

            else:        
                if 'prec' in self.model_definition['constrain_with_harmonics']:            
                    J = self.jacfunc_with_harmonics(popt,self.residuals, p_dict, stresses_dict, heads ,
                                                    selectlog = selectlog_det, selectparam = selectparam_det,delp = delpdef)               
                else:
                    J = self.jacfunc(popt, self.residuals, selectlog = selectlog_det, delp = delpdef) 
            
                
            g = np.dot(np.transpose(J),res_old)


        else:
                      
            if analytical_jacobian == True:
                J = self.jacanalytical(popt)
                
      
            else:
                if 'prec' in self.model_definition['constrain_with_harmonics']:    
                    J = self.jacfunc_with_harmonics(popt,self.noise, p_dict, stresses_dict, heads, 
                                                    selectlog = selectlog, selectparam = selectparam ,delp = delpdef)    
    
                else:
                    J = self.jacfunc(popt, self.noise, selectlog = selectlog, delp = delpdef)

            noise_old = self.noise(popt)
            expvarnoiseold = self.goodness_of_fit(popt, noise = True)[0]
            g = np.dot(np.transpose(J),noise_old)
        
        JTJ = np.dot(np.transpose(J),J) # weighing is included in noise function
            
        stop = (np.linalg.norm(g) < eps1)
        # I = np.diag(np.ones(np.shape(J)[1]))
        dim = np.shape(JTJ)[0]
        I = np.identity(dim)
        
        k = 0
        rho_old = 1e9
        dmx_old = 1e9
        indmin_old = 1e9
        mu = 0
        nu = 1.5
        
        delta = 2. #delta determines the size of the steps in the objective function landscape; the bigger delta, the bigger the step;0.1 is slows but will not miss the optimum
        dmax = 1.5
        
        
        while not stop and k < maxiter:
 
            k = k+1
            print('1330 k',k)

            normdp = delta
            
            while normdp >= delta:
                mu = nu*mu + 0.0001
                dp = np.linalg.solve(JTJ + mu*I, g) 

                normdp = np.linalg.norm(dp)
                mask = (dp == 0)
                dp[mask] = 1e-9          
                         
            test_change = (dp/popt) #relative parameter change for non log transformed parameters to optimize
            test_change[selectlog] = (dp-1)[selectlog] #relative parameter change for log transformed parameters to optimize; dp is a vector, and python understands 1 as a vector of ones of length len(dp); this is another example of Python broadcasting
    
            if (max(abs(test_change)) < eps2):
                stop = True
                success = True


            else:
    
                #calculate damping parameter rho according to 'METHODS AND GUIDELINES FOR EFFECTIVE MODEL CALIBRATION by Mary C. Hill,1998'
                converg_test = abs(test_change) > dmax#convergence test
                converg_test = test_change > dmax
                rho = np.ones(len(dp))
                ind = np.flatnonzero(converg_test &~ selectlog)
                rho[ind] = (dmax/abs(test_change))[ind]#this is rho for non log transformed parameters
                ind = np.flatnonzero((converg_test & selectlog) & (dp > 0))
                rho[ind] = (np.log(dmax + 1)/dp)[ind]
    
                if dmax > 1: #this was wrong in former versions! Check again how it was in guideline Mary Hill
                    ind = np.flatnonzero((converg_test & selectlog) & (dp<0))
                    rho[ind] = (np.log(dmax-1)/dp)[ind]
                indmin = np.argmin(rho)#returns the indice of the minimum rho
                rho_min = min(rho)
     
                #apply oscillation control
                dmx = dp[indmin]/abs(popt[indmin])#dmx is d relative min, this is DMX of Mary Hill guide line
                if k == 1 or indmin != indmin_old:
                    rho_star = 1
                else:
                    s = dmx/(rho_old*dmx_old)
                    if s >= -1:
                        rho_star = (3+s)/(3+abs(s))
                    else:
                        rho_star = 1/(2*abs(s))
                rho = rho_star*rho
                
                dmx_old = dmx
                indmin_old = indmin
                rho_old = rho[indmin]
                
                #ptry = popt + dp*rho
                
                ptry = popt + dp
                
                
                ptry_full = p_dict['p_init']
                ptry_full = np.array(ptry_full)
                ptry_full[selectparam] = ptry
                p_dict['p'] = ptry_full.tolist()
        
                # sim = Simulation(time, p_dict, stresses_dict,time_step = None, Nint_dict = None, tminnum = tmin_sim, tmaxnum = tmax_sim, settings = None).simulate()
                # simulation_det = sim[targets_selector,1] #deterministic simulation

                if 'prec' in self.model_definition['constrain_with_harmonics']:
                    p_dict = update_P_given_harmonic_components(p_dict, stresses_dict, heads)
            
                # sim = Simulation(time = time, p_dict = p_dict, stresses_dict = stresses_dict, 
                #      heads = heads, time_step = time_step, Nint_dict = Nint_dict, 
                #      tminnum = tmin_sim, tmaxnum = tmax_sim, settings = settings, 
                #      model_residuals = False, model_definition = md).simulate()
                # simulation_det = sim[targets_selector,1] #deterministic simulation
                res_new = self.residuals(ptry)
                   
                # res_new = np.dot(np.diag(weights),res_new)
                # SSreg_res_new = sum(pow(res_new,2))
                # expvarnew = 100*(1-SSreg_res_new/SStot)
            
                expvarnew = self.goodness_of_fit(ptry, noise = False)[0]
                
                                              
                if model_residuals == True: 
                    noise_new = self.noise(ptry)
                    # SSreg_noise_new = sum(pow(noise_new,2)) 
                    # expvarnoisenew = 100*(1-SSreg_noise_new/SStot)  
                    expvarnoisenew = self.goodness_of_fit(ptry, noise = True)[0]
                    
                if model_residuals == False: 
                    condition = expvarnew > expvarold
                    #condition=SSreg_res_new<SSreg_res_old
                    message = (f'line 1425: expvarold = {expvarold:.2f}')
                    print(message)
                    message = (f'line 1427: expvarnew = {expvarnew:.2f}')
                    print(message)                    

                    
                else:
                    message = (f'line 1432: expvarold = {expvarold:.2f}')
                    print(message)
                    message = (f'line 1434: expvarnew = {expvarnew:.2f}')
                    print(message)                    
                    message = (f'line 1436: expvarnoiseold = {expvarnoiseold:.2f}')
                    print(message)
                    message = (f'line 1438: expvarnoisenew = {expvarnoisenew:.2f}')
                    print(message)                      

                    condition = (expvarnoisenew > expvarnoiseold) and (expvarnew > expvarold)
                    #condition = expvarnew > expvarold
                      
    
                if condition == True:
                    mu = 0
                    popt = ptry
                    popt_full = []

                    for e in p_dict['p_init']:
                        popt_full.append(e)

                    popt_full = np.array(popt_full)
                    popt_full[selectparam] = popt
                    p_dict['p'] = popt_full.tolist()
                    
                    res_old = res_new
                    expvarold = expvarnew                         
                        
                    if model_residuals == True:                                    
                        noise_old = noise_new 
                        expvarnoiseold = expvarnoisenew
                                                                                                                                                                                                                                                 
                    if expvarnew > best_score: #to keep the parameters that provide the highest expl variance (so we dont minimize the sum of squared residuals!)
                        best_score = expvarnew
                        best_p = popt_full

                        
                    if model_residuals == False:
                        
                        if analytical_jacobian == True:
                            J = self.jacanalytical(ptry)
                               
                        else:
                            
                            if 'prec' in self.model_definition['constrain_with_harmonics']:    
                                J = self.jacfunc_with_harmonics(ptry,self.residuals, p_dict, stresses_dict, heads, 
                                                                selectlog = selectlog_det, selectparam = selectparam_det ,delp = delpdef)    
                            else:
                                J = self.jacfunc(ptry, self.residuals, selectlog = selectlog_det, delp = delpdef) 
                            
                        g = np.dot(np.transpose(J),res_new)
                        stop = (np.linalg.norm(g) < eps1) or (np.linalg.norm(res_new) < eps3)                        
                        
                    else:
                        noise_new = self.noise(popt)
                        
                        if analytical_jacobian == True:
                            J = self.jacanalytical(ptry)
                               
                        else:                        
                        
                            if 'prec' in self.model_definition['constrain_with_harmonics']:    
                                J = self.jacfunc_with_harmonics(ptry,self.noise, p_dict, stresses_dict, heads, 
                                                                selectlog = selectlog, selectparam = selectparam ,delp = delpdef)    
                            else:
                                J = self.jacfunc(ptry, self.noise, selectlog = selectlog,  delp=delpdef)
        
                        g = np.dot(np.transpose(J),noise_new)
                        stop = (np.linalg.norm(g) < eps1) or (np.linalg.norm(noise_new) < eps3)             
    
   
                else:
                    
                    print('1556 modify Levenberg-Marquardt damping parameter mu through delta and nu')
                    delta = delta / 1.5
                    nu *= 1.5
                    # print('1556 switch to numerical Jacobian and modify Levenberg-Marquardt damping parameter mu ')
    
                    # if model_residuals == False:                        
                        
                    #     if 'prec' in self.model_definition['constrain_with_harmonics']:    
                    #         J = self.jacfunc_with_harmonics(ptry,self.residuals, p_dict, stresses_dict, heads, 
                    #                                         selectlog = selectlog_det, selectparam = selectparam_det ,delp = delp)    
                    #     else:
                    #         J = self.jacfunc(ptry, self.residuals, selectlog = selectlog_det, delp = delp) 
                    #     g = np.dot(np.transpose(J),res_old)
                    #     stop = (np.linalg.norm(g) < eps1) or (np.linalg.norm(res_old) < eps3)                        
                        
                    # else:
                    #     noise_new = self.noise(popt)
                        
                    #     if 'prec' in self.model_definition['constrain_with_harmonics']:    
                    #         J = self.jacfunc_with_harmonics(ptry,self.noise, p_dict, stresses_dict, heads, 
                    #                                         selectlog = selectlog, selectparam = selectparam_det ,delp = delp)    
                    #     else:
                    #         J = self.jacfunc(ptry, self.noise, selectlog = selectlog,  delp=delp)
    
                    #     g = np.dot(np.transpose(J),noise_old)
                    #     stop = (np.linalg.norm(g) < eps1) or (np.linalg.norm(noise_old) < eps3)                                
                        
 
                        


        if model_residuals == False:
            
            if analytical_jacobian == True:
                J = self.jacanalytical(popt)                
            
                if 'prec' in self.model_definition['constrain_with_harmonics']:    
                    J = self.jacfunc_with_harmonics(popt,self.residuals, p_dict, stresses_dict, heads, 
                                                    selectlog = selectlog_det, selectparam = selectparam_det ,delp = delp)    
                else:
                    J = self.jacfunc(popt, self.residuals, selectlog = selectlog_det, delp = delpdef)                     
                
        else:
            
            if analytical_jacobian == True:
                J_with_noise_model = self.jacanalytical(popt)       
                
            else:    
                if 'prec' in self.model_definition['constrain_with_harmonics']:    
                    J_with_noise_model = self.jacfunc_with_harmonics(popt,self.noise, p_dict, stresses_dict, heads,
                                                    selectlog = selectlog, selectparam = selectparam ,delp = delp)    
                else:
                    J_with_noise_model = self.jacfunc(popt, self.noise, selectlog = selectlog,  delp=delpdef)

        # J = np.dot(np.diag(weights),J)
        JTJ = np.dot(np.transpose(J),J)
        
        
        p_dict['p'] = popt_full
        

        if 'prec' in self.model_definition['constrain_with_harmonics']:
            p_dict = update_P_given_harmonic_components(p_dict, stresses_dict, heads)


        res = self.residuals(popt)
        # res = np.dot(np.diag(weights),res)
        # SSreg_res = sum(pow(res,2))
        # expvar = 100*(1 - SSreg_res/SStot)
        expvar = self.goodness_of_fit(popt)[0]
        expvarnoise = None
        residuals = res

        pcov = np.linalg.inv(JTJ)*np.var(res)

        pvar = np.diag(pcov) #parameters variance vector
        pstdev = np.sqrt(pvar) #parameters standard deviation vector

        
        outer_product = np.outer(pstdev,pstdev)#outer product of standard error vector
        pcor = pcov / outer_product  

        if not isinstance(self.heads,list):
            heads_list = [self.heads]
        else:
            heads_list = self.heads      
        
        
        ind_begin = 0
        for heads in heads_list:
            ind_end = ind_begin + len(heads.interpolated)

            _fitgoodness = {}
            _fitgoodness['pcov'] = pcov
            _fitgoodness['pcor'] = pcor
            _fitgoodness['pstdev'] = pstdev

            expvar = self.goodness_of_fit(popt, heads = heads)[0]

            _fitgoodness['expvar'] = expvar
            heads.fitgoodness = _fitgoodness
            heads.p_dict = p_dict
            
            simulation = Simulation(time = time, p_dict = p_dict, stresses_dict = stresses_dict, 
            heads = heads, time_step = time_step, Nint_dict = Nint_dict, 
            tminnum = tmin_sim, tmaxnum = tmax_sim, settings = settings, 
            model_residuals = False, model_definition = md)
            
            sim = simulation.simulate()

            heads.modeled = sim
            heads.residuals = residuals[ind_begin:ind_end]
            
            modeled_normalized = np.empty(np.shape(sim))
            modeled_normalized[:,:] = sim[:,:]
            mean = np.mean(sim[:,1])
            modeled_normalized[:,1] -= mean 

            heads.modeled_normalized = modeled_normalized
            harmonic_modeled = Harmonics(modeled_normalized).fit_harmonic()
            heads.harmonic_modeled = harmonic_modeled
            

            ind_begin = ind_end
            for stress_type in self._stresses_dict:
      
                for e in simulation.components[stress_type]:

                    simulated_component = simulation.components[stress_type][e]
 
                    simulated_component_normalized = np.empty(np.shape(simulated_component))
                    simulated_component_normalized[:,:] = simulated_component[:,:]
                    mean = np.mean(simulated_component[:,1])
                    simulated_component_normalized[:,1] -= mean     
                    
                    self._stresses_dict[stress_type][e].modeled_normalized = simulated_component_normalized

                    harmonic_input = np.empty(np.shape(simulated_component_normalized))
                    harmonic_input[:,:] = simulated_component_normalized[:,:]

                    if stress_type in ['evap','well']:
                        harmonic_input[:,1] *= -1
                    
                    self._stresses_dict[stress_type][e].harmonic_modeled = Harmonics(harmonic_input).fit_harmonic()


                    if stress_type in ['prec','evap','well']:

                        message = (f'\nIn class {clsname} of module {modulename}.py: '
                                   f'harmonic of simulated is divided by time_step for prec, evap and well.\n')                          
                        logger.warning(message)
                        self._stresses_dict[stress_type][e].harmonic_modeled.harmonic_component[:,1] /= self.time_step
                        self._stresses_dict[stress_type][e].harmonic_modeled.amplitude[0] /= self.time_step # amplitude value
                        self._stresses_dict[stress_type][e].harmonic_modeled.amplitude[1] /= self.time_step # standard deviation of amplitude



        # except LinAlgError:   
        #     message = (f'\nIn class {clsname} of module {modulename}.py: '
        #                'Covariance matrix could not be evaluated.\n ')                      
        #     logger.warning(message)                  
        #     pcov = None    
        #     pcor = None
        #     pstdev = None            
    

        if model_residuals == True: 

            noise = self.noise(popt) 
            expvarnoise = self.goodness_of_fit(ptry, noise = True)[0]
            
            # try:
            JTJ = np.dot(np.transpose(J_with_noise_model),J_with_noise_model)
            pcov = np.linalg.inv(JTJ)*np.var(noise)
            pvar = np.diag(pcov)#parameters variance vector
            pstdev = np.sqrt(pvar)#parameters standard deviation vector
            outer_product = np.outer(pstdev,pstdev)#outer product of standard error vector
            pcor = pcov / outer_product   

            if not isinstance(self.heads,list):
                heads_list = [self.heads]
            else:
                heads_list = self.heads    
                          
            ind_begin = 0
            for heads in heads_list:
                ind_end = ind_begin + len(heads.interpolated)

                _fitgoodness_with_residuals = {}
                _fitgoodness_with_residuals['expvar'] = expvar
                _fitgoodness_with_residuals['pcov'] = pcov
                _fitgoodness_with_residuals['pcor'] = pcor
                _fitgoodness_with_residuals['pstdev'] = pstdev

                expvar = self.goodness_of_fit(popt, heads = heads, noise = True)[0]
                _fitgoodness['expvar'] = expvar
                heads.fitgoodness = _fitgoodness
                heads.p_dict = p_dict                

                simulation_with_residuals = Simulation(time = time, p_dict = p_dict, stresses_dict = stresses_dict, 
                            heads = heads, time_step = time_step, Nint_dict = Nint_dict, 
                            tminnum = tmin_sim, tmaxnum = tmax_sim, settings = settings, 
                            model_residuals = True, model_definition = md).simulate()
                
                heads.simulated_with_residuals = simulation_with_residuals
                heads.noise =  noise[ind_begin:ind_end]
                ind_begin = ind_end

            # except LinAlgError:   
            #     message = (f'\nIn class {clsname} of module {modulename}.py: '
            #                'covariance matrix could not be evaluated.\n ')                      
            #     logger.warning(message)   
            #     expvarnoise = None
            #     pcov = None    
            #     pcor = None
            #     pstdev = None
            #     fitgoodness_with_residuals = {}
            #     fitgoodness_with_residuals['expvar'] = expvar
            #     fitgoodness_with_residuals['pcov'] = pcov
            #     fitgoodness_with_residuals['pcor'] = pcor
            #     fitgoodness_with_residuals['pstdev'] = pstdev        
            #     self.heads.fitgoodness_with_residuals = fitgoodness_with_residuals
                        

        # except:

        #     message = (f'\nIn class {clsname} of module {modulename}.py: failed finding an optimum.\n')     
        #     logger.error(message)     
        #     pcov = None
        #     pcor = None
        #     pstdev = None
        #     p_dict = None
        #     expvar = None
        #     expvarnoise = None
        
        return popt, pcov, pcor, pstdev, p_dict, expvar, expvarnoise    
    
    
    @staticmethod
    def sacf(X, lag=1):
        """
        Function to evaluate the sample autocorelation at a given lag

        Parameters
        ----------
        X: numpy array_like
                time series of values
                
        lag: integer
             lag for which the autocorrelation is evaluated   
             
        References
        ----------
        Modified from  Dr. Ernesto P. Adorio
        UPDEPP at Pampanga (UP Clarkfield)
        """
        flen = float(len(X))
        xbar = float(sum([x for x in X])) / flen # xbar is x average
        D = sum([(x-xbar)**2 for x in X])
        N = sum([ (x-xbar) * (xtpk -xbar) for (x, xtpk) in zip(X[:-lag],X[lag:])])
        
        return N/D


    
    @staticmethod
    def sacf_with_CI(X, lag=1, alpha=0.05):
    
        """
        Function to evaluate the sample autocorelation 
        with the lower and upper bounds of a standard normal 
        distribution
        
        Parameters
        ----------
        X: numpy array_like
                time series of values
                
        lag: integer
             lag for which the autocorrelation is evaluated   
             
        alpha: float
             arbitrary threshold for statistical significance                
             

        References
        ----------        

        adapted from Dr. Ernesto P. Adorio
        Note :
        According to wikipedia https://en.wikipedia.org/wiki/Correlogram, 
        if the correlogram is being used to test for randomness
        (i.e., assume no time dependence in the time series values), the following formula is recommended
        for confidence bands:
        lci = -Zalpha/sqrt(len(sample))   with lci = lower confidence interval 
        uci = -Zalpha/sqrt(len(sample))   with lci = upper confidence interval 
        Z is the quantile function of the standard normal distribution and alpha is the significance level.
        In this case, the confidence bands have fixed width that depends on the sample size.
        This is not the same as draw upper and lower bounds for autocorrelation samples with significance level
        using for example Barlett's formula
        """
        
        from scipy.stats import norm
        
        T     = float(len(X))
        rho   = Poptimizer.sacf(X, lag = lag)
        # Ztest = rho * np.sqrt(T)
        Zcrit = norm.ppf(alpha/2.0)
        lcl   = Zcrit/np.sqrt(T)
        ucl   = -lcl

        return lcl,rho,ucl       
    
    
        
    @staticmethod
    def autocorrelation(X,lagtime=1, alpha = 0.05):
        """
        A method to evaluate a sample of time series autocorrelation
        
        Parameters
        ----------    
        
        X: numpy array_like
                time series of values
                
        
        plot_title: string (optional)
                string specifying plot title 
                
        save_plot: boolean (optional)
            Boolean variable specifying if the plot is to be saved on disk
            
        alpha: float
             arbitrary threshold for statistical significance      
        
        """

        N = len(X)
        
        lags = np.arange(0,N)

        
        t = lags*lagtime
        acfsample = np.zeros((N,3)) # declare sample autocorrelation array, with lower and upper confidence interval

        for k in range(0,N):
            lci,rho,uci = Poptimizer.sacf_with_CI(X, lag=k, alpha=alpha)

            acfsample[k,0] = lci
            acfsample[k,1] = rho
            acfsample[k,2] = uci
        
        SE = np.ones((N,1)) # declare standard error array 
        summ = 1
        for k in range(1,N):       
            rho   = Poptimizer.sacf(X, lag=k) 
            summ += rho**2
            SE[k] = np.sqrt(1+2*summ)

        SE /= np.sqrt(N)
            
        
        def residuals_function(a,t,acfsample):
            return np.exp(-a*t) - acfsample[:,1]
        
        
        a0 = 0.1
        outcome = leastsq(residuals_function,a0,args=(t,acfsample),full_output=1,Dfun=None, col_deriv=0, ftol=1.e-10, xtol=1.e-12, gtol=0.0, maxfev=0, epsfcn=0.0, factor=0.1, diag=None)
        
        a = outcome[0]
        
        
        return acfsample, a, t, SE        

    
    def residuals_check_diagrams(self, heads = None, save_plot = False, alpha = 0.05):
        
        """ 
        A method to plot residuals check diagrams.
        
        Parameters
        ----------    
        
        heads : Heads object or list of Heads objects
        Heads object  containing the observed groundwater levels,
        associated metadata and preprocessed versions of the groundwater level time series 
        
        plot_title: string (optional)
                string specifying plot title 
                
        save_plot: boolean (optional)
            Boolean variable specifying if the plot is to be saved on disk
            
        alpha: float
             arbitrary threshold for statistical significance                
             

        """
        
        clsname = str(self.__class__.__name__)
        modulename = str(__name__)   
        
        observed = heads.observed
        interpolated = heads.interpolated
        tseries_type = heads.tseries_type
        residuals_series = heads.residuals
        noise_series = heads.noise
            
        list_of_residuals_series = []
        list_of_residuals_series_types = []
        
        if residuals_series is not None: 
            list_of_residuals_series.append(residuals_series)
            list_of_residuals_series_types.append('residuals')

        if noise_series is not None: 
            list_of_residuals_series.append(noise_series)        
            list_of_residuals_series_types.append('noise')

        for i in range(0,len(list_of_residuals_series)) :
            
            residuals_series = list_of_residuals_series[i]
            series_type = list_of_residuals_series_types[i]

            
            left_margin = 0.07
            right_margin = 0.07
            top_margin = 0.10
            bottom_margin = 0.14
            dy = 0.07
            dx = 0.07        
    
            fs = 12
            # from matplotlib import rcParams
            # rcParams['font.size'] = fs#This is to change default font size
            colors = ['b-','m-','y-','c-','g-', 'tab:green-','tab:olive-', 'tab:purple-','tab:pink-','tab:orange-','tab:brown-']
                
            
            
            nc = 3
            nl = 1
            plot_length = (1-left_margin-right_margin-dx*(nc-1))/nc
            plot_height = (1-bottom_margin-top_margin-dy*(nl-1))/nl
            x1 = left_margin
            y1 = 1-top_margin-plot_height
            X = [x1]
            Y = [y1]
            for i in range(1,nc):
                X.append(X[i-1]+plot_length+dx)
                   
            for i in range(1,nl):
                Y.append(Y[i-1]-plot_height-dy)
    
            fig = figure(num = None, figsize=(6*nc,6),dpi=50,facecolor='w', edgecolor='k')# figsize=(width, height) in inches.        
        
            ax1 = fig.add_axes([X[0],Y[0],plot_length,plot_height],frameon=True, xscale=None, yscale=None) 
            
            
            
            from pylab import hist
            from scipy.stats import shapiro,norm
            #majorticks=[-0.1,-0.075,-0.050,-0.025,0,0.025,0.05,0.075,0.1]
            majorticks = [-0.1,-0.05,0,0.05,0.1]
            minorticks = np.arange(-0.1,0.11,0.01)
            majorLocator = FixedLocator(majorticks)
            minorLocator = FixedLocator(minorticks)
            ax1.xaxis.set_minor_locator(minorLocator)
            ax1.xaxis.set_major_locator(majorLocator)
            ax1.xaxis.set_ticks_position('bottom')
            mu_norm, scale_norm = norm.fit(residuals_series)
            distribution = norm(loc=mu_norm,scale=scale_norm)
            xvalues = np.linspace(mu_norm-3*scale_norm,mu_norm+3*scale_norm)
            pdf = distribution.pdf(xvalues)
            ax1.set_xlabel('residuals (m)',fontsize=fs)
            ax1.set_ylabel('number of residuals per bin',fontsize=fs)
            ax1.hist(residuals_series,bins=minorticks,density=True)
            ax1.set_xlim(-0.15,0.15)
            ax1.plot(xvalues,pdf,'r',linewidth=2)
            for tick in ax1.xaxis.get_major_ticks():
                tick.label.set_fontsize(fs)
                #tick.label.set_rotation(20)
            for label in ax1.xaxis.get_majorticklabels():
                #ha=label.get_horizontalalignment()
                #label.set_horizontalalignment('right')
                label.set_horizontalalignment('center')
            ax1.grid(True)
            x_text = 0.05
            y_text = 0.95
            ax1.annotate('a)', xy=(x_text, y_text), xycoords='axes fraction',horizontalalignment='left', verticalalignment='center',fontsize=fs)

            
            ax2 = fig.add_axes([X[1],Y[0],plot_length,plot_height],frameon=True, xscale=None, yscale=None)         
            deviation_from_mean = heads.modeled[:,1] - np.mean(heads.modeled[:,1])
                
            ax2.plot(deviation_from_mean[heads.targets_selector],residuals_series,'r+')
            ax2.set_xlabel('deviation from mean simulated head (m)',fontsize=fs)
            ax2.set_ylabel('residuals (m)', fontsize=fs)
                
            ticks = np.arange(-0.15,0.2,0.05)
            majorLocator  = FixedLocator(ticks)
            ax2.yaxis.set_major_locator(majorLocator)
            ax2.set_ylim(ticks[0]-0.02,ticks[-1]+0.02)    
                
            for tick in ax2.xaxis.get_major_ticks():
                tick.label.set_fontsize(fs)
            for tick in ax2.yaxis.get_major_ticks():
                tick.label.set_fontsize(fs)
            ax2.annotate('b)', xy=(x_text, y_text), xycoords='axes fraction',horizontalalignment='left', verticalalignment='center',fontsize=fs)
            
            x_title = -0.01
            y_title = 1.07
            title = 'Diagnostic plots for '+ series_type + ' time series'
            ax2.text(x_title,y_title,title,fontsize=14,rotation='horizontal',ha='left', va='center',transform=ax2.transAxes)
            
            
            ax3 = fig.add_axes([X[2],Y[0],plot_length,plot_height],frameon=True, xscale=None, yscale=None)  

            acfsample, a, t, SE = Poptimizer.autocorrelation(residuals_series, lagtime = self.time_step_targets)
    
            model = np.exp(-a*t)
            
            ax3.plot(t,acfsample[:,2],'g--')
            ax3.plot(t,acfsample[:,1],'b')#sample autocorrelation function
            #ax3.plot(t,mod,'r')#autocorrelation function
            ax3.plot(t,acfsample[:,0],'m-.')
            ax3.set_xlabel('time (days)',fontsize=fs)
            ax3.set_ylabel('autocorrelation',fontsize=fs)
            for tick in ax3.xaxis.get_major_ticks():
                tick.label.set_fontsize(fs)
            for tick in ax3.yaxis.get_major_ticks():
                tick.label.set_fontsize(fs)
            ax3.set_ylim(-1,1)
            leg = ax3.legend((str(int(alpha*100))+'% upper confidence interval','sample residuals autocorrelation',str(int(alpha*100))+'% lower confidence interval'),loc='lower left',shadow=False)
            ax3.text(x_text,y_text,'c)',fontsize=fs,rotation='horizontal',ha='left', va='center',transform=ax3.transAxes)
             
            show()
            
                
            
            if save_plot == True:
                if self.name is not None:
                    figname = "plot_of_{}".format(self.name)
                else:
                    figname = "time_series_plot"
                try: 
                    abs_path=os.path.dirname(os.path.abspath(__file__))
                    abs_path_splitted=abs_path.split('\\')
                    path_to_parent_folder_elements=abs_path_splitted[:-1]
                    path_to_parent_folder=os.path.join(*path_to_parent_folder_elements)
                    splitted=path_to_parent_folder.split(':')#trick  to  repair  path
                    path_to_parent_folder=splitted[0]+':\\'+splitted[1]#trick  to  repair  path
                    path_to_file_folder=os.path.join(path_to_parent_folder,'results')
                    savefig(path_to_file_folder+'\\'+figname, dpi=None, facecolor='w', edgecolor='w',orientation='portrait', format=None,transparent=False, bbox_inches=None, pad_inches=0.1)
                  
                except:
                    curdir=os.getcwd()
                    savefig(curdir+'\\'+figname, dpi=None, facecolor='w', edgecolor='w',orientation='portrait', format=None,transparent=False, bbox_inches=None, pad_inches=0.1)
                           
        

            
        return
    
    

if __name__ == "__main__":
    #curdir=os.getcwd()
    abs_path = os.path.dirname(os.path.abspath(__file__))
    abs_path_splitted = abs_path.split('\\')
    path_to_parent_folder_elements = abs_path_splitted[:-1]
    path_to_parent_folder = os.path.join(*path_to_parent_folder_elements)
    splitted = path_to_parent_folder.split(':')#trick  to  repair  path
    path_to_parent_folder = splitted[0]+':\\'+splitted[1]#trick  to  repair  path
    path_to_file_folder = os.path.join(path_to_parent_folder,'resources') 
    
    stresses_dict = {}

    
    ######################## Test using a piezometer on de Sallands sand ridge in the Netherlands

    path_to_file = os.path.join(path_to_file_folder,'672_PREC_Hellendoorn_19510101_20160731_corrected_for_interception2mm.csv')
    path_to_file = os.path.join(path_to_file_folder,'672_PREC_Hellendoorn_19510101_20160731.csv')
    
    
    key = basename(path_to_file)
    stresses_dict['prec'] = {}
    stresses_dict['prec'][key] = Stress.read_from_csv(path_to_file, stress_type = 'prec',cumulative = True)    
    

    path_to_file=os.path.join(path_to_file_folder,'260_De_Bilt_EVAP_19010101_20200910.csv')
    path_to_file=os.path.join(path_to_file_folder,'260_De_Bilt_EVAP_19010101_20131015.csv')
   
    key = basename(path_to_file)
    stresses_dict['evap'] = {}
    stresses_dict['evap'][key] = Stress.read_from_csv(path_to_file, stress_type = 'evap',cumulative = True)    
    
    
    tminstr = '31-12-1981 00:00:00'
    tmaxstr = '31-12-2005 00:00:00'
    
    tminstr = '31-12-1981 00:00:00'
    tmaxstr = '31-12-1995 00:00:00'    
    
    path_to_file_folder = os.path.join(path_to_parent_folder,'resources')  
    path_to_file = os.path.join(path_to_file_folder,'28AP0093_1.txt')
    # heads = Heads.read_from_csv(path_to_file)
    heads = Heads.read_from_csv(path_to_file, tminstr = tminstr, tmaxstr = tmaxstr)
    

    arguments_dict = {}

    for key in stresses_dict:
        for e in stresses_dict[key]:
            stresses_dict[key][e].plot()

    md = ModelDefinition().model_definition
    memory_dict = ModelDefinition().memory_dict
    parametersLogistic = ParametersLogistic(md)
    
    # time_step = 1./(24.*2)
    # time_step_targets = 1.5
    
    time_step = 1.
    time_step_targets = 14.
    
    
    preprocessed = Preprocessed(heads = heads,stresses_dict = stresses_dict, time_step = time_step,
                                time_step_targets = time_step_targets, memory_dict = memory_dict,tminstr = tminstr, 
                                tmaxstr = tmaxstr, model_definition = md).preprocess() 
        
    time = preprocessed.time
    time_step = preprocessed.time_step
    heads = preprocessed.heads

    stresses_dict = preprocessed.stresses_dict 
    Nint_dict = preprocessed.Nint_dict
    all_data_for_neural_networks = preprocessed.all_data_for_neural_networks
    all_targets_for_neural_networks = preprocessed.all_targets_for_neural_networks        
        
    if isinstance(heads,list):
        _heads = heads[0]
    else:
        _heads = heads    
 
    parametersLogistic = ParametersLogistic(md,stresses_dict = stresses_dict, heads = _heads)
    p_dict = parametersLogistic.assemble_p()
    

    # arguments_dict = {}
    # arguments_dict['Xriv'] = 173699.
    # arguments_dict['Yriv'] = 398423.  
    
    settings = {}
    settings['all_piezometers_share_same_model'] = True
    

    arguments_dict = {}

    potimizer = Poptimizer(heads = heads, time = time, p_dict = p_dict, time_step = time_step,time_step_targets = preprocessed.time_step_targets,
                            stresses_dict = stresses_dict, model_residuals = True, model_definition = md,
                            Nint_dict = Nint_dict, arguments_dict = arguments_dict, settings = settings,
                            analytical_jacobian = True, maxiter = 150)    
    

    popt, pcov, pcor, pstdev, p_dict, expvar, expvarnoise  = potimizer.poptimizer_home_brew()    
    
    

    
    ax = potimizer.residuals_check_diagrams(heads = heads)

    to_plot = [heads.interpolated, heads.modeled]
    legend_list = ['interpolated observations', 'modeled']
    
    plotax = heads.plot(tseries_list = to_plot, legend_list = legend_list, share_axes = True )
    output_string = heads.generate_output(model_definition = md)
    print('1848 output_string: ',output_string)   
    
